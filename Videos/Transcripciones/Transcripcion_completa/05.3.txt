05.3-Descriptor tf-idf
https://www.youtube.com/watch?v=BfJ6coSTE_M
 como calculamos descriptores de texto supongamos que tenemos un set de n de documentos del y que el vocabulario lo calculamos y ese tamaño vamos vamos a tener el tamaño del vocabulario que era el 85.000 ambiente nos vamos de nuestros datos este ejemplo y para cada documento siguiendo el modelo para con fuertes vamos a calcular un vector destinación 85.000 ideal que es que quien va a ser va a ser un peso por cada una de las palabras del vocabulario en cada documento y el doble el peso o la relevancia de la décima palabra del del vocabulario en el jota de simón tu mente y esto nos va a dar una matriz de escritores y los pesos y vamos definir bien los pesos tienen que ser todos positivos para hacerlo más fácil y que en él sí que el peso es cero es sí sólo así el el término no está dentro de dentro del documento de que es un caso como 285 mil palabras y en un documento no hasta las 75 mil palabras se van a ver algunas de ellas y las que no estando las de los 0 y las que sí están tristes algo distinto a hacer y en principio lo que vamos a siempre empleando de lo que tiene que ver con que él va a ser un preso no está de fiesta sería el modelo binario modelo juliano donde se es que una palabra está en un 10 y por tanto vamos de descriptores un vector de dimensión 85.000 con de unos y ceros 11 donde hay una palabra este análisis y porque cualquier mina con este bono julián o no sea 0 4 binario mejor que se llama william o porque podemos pasar a hacerte ver operaciones lógicas y en la consulta entonces vamos a preguntar sobre si es que los tenemos los dos momentos que tengan cierta condición esos términos que tiene cierta palabra o que no esté tomás en cannes yours y en este caso la relevancia de un documento va a cumplir con esa condición de la consulta o no lo va a cumplir de final y por tanto si es que lo cumple es relevante si se retorna vicentino lo cumplen he aquí un pequeño ejemplo donde son los que tenemos tres palabras tres términos y los documentos enterrase para estar en alguna de estas zonas dependiendo a si es que está o no está cada uno de los términos en este documento y la consulta entonces son lógicas las fórmulas si queremos todos los documentos recuerden todos los momentos que tengan pequeños y que tengan al término de o no tenga la terminación que trata como como cómo resuelve esta consulta como encuentre los documentos que cumplan con esto en forma eficiente lo que hay que hacer es que para cada documento nosotros ayer le calculamos tienes un escritor y su descriptor va a ser un descriptor binario de entre las coordenadas si es que está ahora está cada uno de estos tres términos y la consulta tenemos que trabajar un poco mediante operaciones lógicas para para llevar esta consulta que se llama la forma de normal dijo que es eso work for the hands es la forma normal digital y en estiramientos amports y esto son fans esta consulta haciendo desarrollando la lógica y distribuyéndola sobre el sol y luego jugando con las negaciones digamos a que esta consulta es es lo mismo que le llama la forma normal de comentar camps aquí es lo mismo que artística el primer término al segundo tema tercer término porque el primero y el tercero primero y ahí está el desarrollo después de haber operado sobre la consulta gráficamente esto significa ir a buscar los dos momentos que están en estas zonas es un honor como en honor y en ante y es bien fácil de resolver porque cada uno hace una sola y por separado y uno va viendo buscar los documentos que cumpla con estas condiciones y empresariales jairo busque aquí activos de hay que tener en que ahora está suenan las listas de ellos documentos y después entonces una consulta se resuelve convirtiendo la fórmula normal de junta y eso lo que obtienen los documentos que cumplen algunas condiciones y el documento será relevante dice que existe y que cumple algunos besos de esos de sus cláusulas y dice que la cumple sí sé que existe alguna cláusula dentro de la consulta que sus pesos siguen iguales los presumiendo momento entonces se vuelve el documento su similitud cumple con la consola y esto de aquí es clave la similitud es igual a decir cumple cumple con el documento completo o no y eso es una propiedad de este modelo o julián y que es exactamente el modelo juliano por una parte es fácil de entender bien simple pero de su misma ventaja en esa relevancia binaria al menos para recuperación de información el hecho que un documento relevante no sea relevante eso es muy bien bases de datos es como un lenguaje de consulta y que uno decide una consulta y quiero saber todos los documentos que cumplen con esa condición y sheraton porque eso está súper bien cuando una base a ti no quieres hacer consultas en la base de datos pero cuando la persona información al inicio una motivación del curso se diferencia de hace rato porque aquí hay muchas cuando uno pregunta por todos los documentos que tienen la palabra del gato negro son cientos de miles de gatos palabras y documentos que la relevancia importante así que este vuelo mundia no hay que mencionarlo que con un ejemplo de bases de datos y lenguaje consulte y no es lo que estamos buscando para recuperación de información por la cooperación de información necesitamos saber que hay cientos de miles posibles que cumplen con la consulta para que realmente decir cuál es más probable que sea lo que está buscando ya decir hay una necesidad de información del usuario que la consulta [Música] es una consulta binaria usualmente retorna como muy pocos documentos o demasiados goles y lograr encontrar la consulta exacta para encontrar el documento que estoy buscando y eso nos lleva a que de hecho los que los buscadores prevén usar este modelo porque cuando nos consultaba porque tiene que hacerlo simplemente palabra gato antes de negro por el gato blanco y uno buscaba por por haciendo consulta lógica de la palabra y por qué no para grandes así que lo que hay que hacer en realidad sería un modelo vectorial que son pesos pesos nobiliarios sino que algo que nos permite calcular similitudes entre hormonales fin y de esto de lo que están buscando que tengan un máx parcial y están buscando documentos gato negro el gato negro que llegue algo lo más parecido posible que sea un gato negro que lo más relevante los datos gris de lo que es el enfoque más de la información y que permite hacer llamado modelo vectorial la diferencia es que aquí ahora magma maya decirse que estaba hasta el documento vamos a partir haciendo un historial y hacer un conteo de las veces que aparece cada palabra entonces el peso del dólar es su hijo atan el peso del término y en el documento j va a ser el número de repeticiones vamos a llamar la frecuencia propias a su hijo el número de veces que aparece en la palabra y en persona ya sabemos de la ley de de vido anterior que tienen con crear una ley de potencia una distribución una paulo y por tanto es muy probable que se disparen algunos términos de influencia demasiado alta comparado en el resto y eso nos motiva aquí en realidad que el abismo de la frecuencia ahora si aparece una única vez y calculado el organismo en la frecuencia así que correremos todos los pesos en uno y ahí nos aseguramos de los pesos para ninguno y que mientras más frecuente tiene un peso mayor aquí [Música] y esto se le llama el df se llama el mar sin notar estos en este último [Música] bien ahora hay un caso malo y como ya vimos en la distribución de palabras el vocabulario las palabras más frecuentes van a tener un peso mayor y por tanto de la que estas palabras muy frecuentes van a tener siempre un precio muy alto en tonos documento que está en todas partes esto y eso hace que todos los programas nos hagan muy parecida entre sí lo que hay que hacer es que no tenemos el enfoque de la victoria dice creo que aarón importancia las palabras y una palabra aquí está en todas partes está en ti está en todos los documentos que no nos sirven porque lo que nos interesa a discriminar documento puede buscar documentos parecidos y estas palabras que están en todos los documentos están igualando los igualados los documentos y lo que tenemos que entonces resaltar son las palabras que aparecen en pocos documentos de hecho una palabra que aparecen en un documento en dos documentos solamente son muy importantes porque existe una palabra persona única y mi consulta dice esta palabra tengo que encontrar ese único documento y por tanto tendrá un peso alto en el documento la palabra única por la palabra que aparece un único documento que es muy importante para hacer documento para discriminar así que hay una relevancia de los términos que están discriminativo es el término si esto interna están todos la base entonces y en todo momento entonces no se elaboraron pesos 0 y como vamos a calcular eso vamos a calcular en el término que se llama en línea es el inverso documento así porque las vergüenzas documentos el dos firmas y sería en cuanto a él en cuántos documentos aparece el la palabra pero cada vez el nombre entonces lo calcula con respecto al total de documentos y que lo que vamos a hacer pero la palabra que aparece en un documento alto le queremos dar un peso bajo porque ese es el tema que no nos sirve no me interesa y por tanto lo vamos a invertir bien en el inverso en ese peso como el que vamos a calcular el logaritmo sobre el marketing del delta para ser cosa que existe en el n por ejemplo se establece una única vez así que sí que tenemos un término que aparece en un solo documento [Música] ese es el es el techo del ser que el término muy bueno y que hay que dar un salto pero si le damos el peso inversión ingreso de n es un número demasiado grande comparado con todos los otros 4000 comparado con s hay que circular un logaritmo sobre sobre eso para que los pesos quieren más comparables entre sí y aquí está este y df nos va a permitir pesos muy bajos y las palabras que son muy frecuentes notar que el día es sobre el dog más fácil y entonces vamos a ver aquí en nuestro vocabulario vamos a ordenar las palabras por 2000 y es decir lo vamos a poner las palabras más frecuentes que aparecen más dos momentos que usualmente es la palabra que son las más frecuentes globalmente la más frecuente en documentos es la palabra y de hecho a es una palabra muy frecuente de los 4.097 documentos de tan con 2.094 y por tanto tengo que dar un peso muy unida efe tengo que castigar mucho a este término porque no nos permite discriminar nada 27 vamos a calcular el dogma si es bueno min 44 min esto no va a dar de un porcentaje que es el total de documento lo que está este término digamos de ser virgen y vamos a calcular 1 dividió en acción logré de aquí y ahí le vamos a dar un peso muy bajo y encendidas y este [Música] banco más caro y aquí vamos a estar dando los pesos a las palabras mientras aquí estaba bajando la frecuencia le vamos a ir dando una frecuencia y un peso más altos hasta la palabra las más frecuentes las palabras que tienen prudencia 1 que su documento va a ser el logaritmo económica está cediendo entre 6 4 que aunque es del orden de los miles de aciertos como si fueran entre mil y dos mil documentos ahí está contrato más de 10 mil va a ser para ti 6 esto nos dice balkin libre 5 de pernos documentos independiente hablar siempre calcula y nos dice que es tan importante es la palabra para discriminar y para calcular similitud entre anteriores documentos en nuestro sector como vamos a calcular el vector de un documento nuestro escritorio texto es el descriptor de fides y que eso es multiplicar entre fines es decir para cada documento calculamos la frecuencia esa palabra y lo multiplicamos por su líder y qué significa eso que la palabra a seguro que va tienen mucha frecuencia porque está en todas partes pero la vamos a multiplicar por cero o casi cero y por tanto un peso muy bajo en ese documento y así va a ser con todas las palabras más frecuentes aquí les vamos a dar un peso muy alto con y matar al toro a las palabras muy escasas es un escaso son escasas también y por tanto su té efe hacer bajo en pocos momentos van a aparecer pero cuando aparezca barrabrava se va a multiplicar por un buen inglés en general este déficit de f va a dar un peso alto cuando no hay los extremos sino que va a darle en la zona un poco más intermedias donde el tse sea un poco mayor ti 0 y el idea es que sea un poco más sobre los términos que tienen una frecuencia
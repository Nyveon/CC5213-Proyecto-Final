07.7-PCA-Búsqueda por similitud
https://www.youtube.com/watch?v=nG9Yv42H2Vg
 y por último la aplicación que más nos va a interesar en este curso es la de búsqueda próxima a qué se refiere con esto que si tenemos un conjunto descriptores en rey sobre ese conjunto de requieren de animaciones y queremos calcular los vecinos más cercanos de q nr vamos a calcular en realidad vamos a calcular r tan un de prima vamos a calcular una prima de menor dimensión y vamos a calcular que los vamos a llevar con q prima de menor dimensión y vamos a calcular los vecinos más cercanos en el espacio de coordinación y si es que desea funcionar bien y un buen caso en los vecinos más cercanos casi no van a cambiar y es la velocidad que nos hace mucho más red porque tenemos menos animaciones que comparar por tanto el algoritmo consiste de entrenamiento muy intensamente entre comillas consiste en que el conjunto r calculamos que esté a sobre él [Música] y los reducimos y es el que mantenemos en memoria y luego la fase online cuando lleguen los objetos de consulta tenemos que aplicar la cv para llevarlo al cubo al espacio de imaginaciones y ahí vamos a calcular el decir más cercano usando el linares que el bloque que nos garantice el vecino más caro en el espacio aproximado aun cuando somos libres campo estamos usando el inah es crear el espacio aproximado por tanto los k nn en el espacio desde prima dimensiones nos caen en extractos dentro del entre sus vinilos vivas son los k n n aproximados de en el término original y que eso debieran de ser muy parecidos no son exactamente lo mismo pero deberá ser muy parecido dependiendo de cuánta varianza hay en los genes de primas y por tanto hay que tener en cuenta que con este método de búsqueda una búsqueda de verdú que aproximada en la relación de actividades y eficiencias y es que tan rápido vamos a ir y que tanto vamos a fallar como acertar en el vecino veces que no se decidió en la tabla offline cuando donde decimos de prima y gramos es decir cuando ya estamos buscando esto ya está creado el espacio de cómo mejorarla mucho y estado no sólo por de prima es decir si reducimos a la mitad los vectores la búsqueda va a ir el dole racing pero puede que puede que falle mucho o no y eso va a depender de cuánta varianza está reteniendo teniendo suerte prima por tanto depende estos dos valores es la efectividad de de la narración de efectividad eficiencia al buscar compresión vamos a ver un ejemplo donde va [Música] aquí tenemos ya sea y vamos a usar descriptores its de ejemplo eso lo que hemos estado en los otros índices para se va a ser un vector de animación 5.000 son vamos a indexar el espacio de 100 mil vectores de animación 128 para hacer pese a sobre estos datos tenemos que calcular primero centrarnos y cómo lo hacemos calculamos la media estos son el vector del vector promedio y un vector de migración 120 h y esto se lo vamos a restar alternativo de los datos centrados es decir con media cero sobre esto vamos a calcular la matriz de coreas qué es una matriz de 128 ojo hay que esto está con transporte porque si que no calculamos [Música] entonces intenté calcular la matriz d para calcular una matriz de una matriz de 128 x 128 y sobre eso vamos a calcular la más bien de incoherencias calcular los valores ahí vamos a obtener los 128 valores propios y 128 victorias propias aquí se están mostrando entonces bueno esto se debe a que los 128 menores propios una red de educación es estrecho y los 128 vectores bloques porque el sí mismo no es propio de los valores propios aquí tenemos 128 números y los queremos ordenar de mayor a menor y como lo ordenamos la función para los índices de menor a mayor y aquí los ordenamos en el inverso de mayor a menor no lo usamos en forma inversa y obtenemos los efectos según el mismo orden para mantener nos parece pero entonces como esto es estos van a ser la varianza en el espacio proyectado y aquí hay la varianza 18.900 en el primer eje y luego baja 13.009 miles le iba a ir bajando y las últimas dimensiones que tienen poca barinas y estas son las candidatas a ser eliminadas cómo hacemos eso podemos incluso ver estos ejes porque nos interesa la suma de ellos cómo se relaciona la suma de ellos con respecto a la suma total podemos graficar esto y quiero que estamos aquí y vamos a ir desde la animación por cero aquí vamos a partir desde hasta la animación 128 que tiene toda la varianza y vamos a ir viendo como él si bajamos a la mitad las dimensiones por ejemplo de naciones 64 y en la mitad las dimensiones la varianza total es 94% es decir si tomamos los primeros 64 no nos dejan éstos sumados es la mitad de las casi el 95 keystone dice que el introducir los dos y lo platicamos ahí se ve como la varianza con los primeros ejes principales de las piezas componentes principales se acumula mucha varianza eso también y a partir de cierto punto de hacer cada componente principal de aporta poca varias y por tanto son las cantidades para hacer eliminados y aquí nos cogíamos la mitad del 50 200 activaciones tenemos 92 pero no podemos bajar tanto porque si no vamos arreglando los descriptores si transformamos los vectores por ejemplo eliminación 10 aquí vamos a tener los vectores que quieras de animación 128 los vamos a convertirnos la dimensión 1010 [Música] como podemos comprobar que esto lo estamos haciendo bien así que todos queríamos algún problema y la implementación tenemos que transformar los vectores originales sin transformar buenos victorio originales y los rotamos nos tiene que dar una matriz tiempo varianza ni ahora y cómo transformar un conjunto de datos consiste en hacer primero que restar las mayores centrales dijo aquí que esto provee este promedio es el promedio que usamos para calcular la larga la matriz de nicobar y así nos balón y casi tres partes e y vamos a crear la matriz de transformación que son los primeros y los primeros gestores propias y vamos a calcular la multiplicación de la matriz de datos con la matriz de transformación y nos van a dar lo que tiene están formadas si eso lo hacemos y con los us 128 dimensiones vamos a calcular el rx que usamos para para calcular los valores propios y sobre eso vamos a calcular el espacio que llamaremos reducidos y luego le vamos a calcular la matriz de covarianza al espacio reducido al espacio y el espacio rotado entonces le calculamos la matriz de con varianzas y luego de centrarnos aquí en el central de su vagar 0 y suma tiene como varianzas aquí se está mostrando de una matriz de 128 x 128 con esto no es una sana elevados 42 en realidad es el 18 1962 y los otros son valores muy cercanos a 0 y es hasta se entiende más se quiere decimos 11 el boj y no pagar a estos valores 18 amigos a 113 mil gracias de 9 y esos son los valores que los vinculan un poquito aquí también 18000 3.019 mente y esos son los mismos y si tomamos valores [Música] 4,3 y nos dan valores en ese entonces y nos dicen que esta forma si estaba funcionando de los dos estamos quitándole la correlación los tres porque ya ahora como podemos medir y la efectividad la próxima lo vemos acá para acelerar esto [Música] aquí está calculado para dos data sets al igual que como lo hicimos con cuando cuando evaluamos los índices multidimensionales de los árboles vamos tener 22 tapas & 2 de dimensión 128 pero son descriptores distintos dónde quiere decir que es una imagen y estos son descriptores makers son de austin todos tienen la misma dimensionalidad pero tienen dos distribuciones muy distintas y vamos a calcular pese a cómo íbamos hablando con la búsqueda de los destinos más cercanos cómo vamos a hacer esto vamos viendo a calcular parecido como decimos antemano calcular un linares que hay en el espacio original y eso nos va a dar los vecinos más cercanos según el ska línea luego vamos a calcular especial sólo usando como matiz de covarianza el data set r de grandes inventores y luego vamos a ir haciendo proyecciones a menor dimensión vamos a calcular el vecino más cercano en el espacio proyectado y vamos a comparar donde se ve la búsqueda vamos a comparar cuántas iguales tiene con respecto a lo que lo que encontramos con bloques y los más cercanos con la línea es carreras original así es lo mismo que lo obtenido por la línea scan de una recta vor actualice quien es lo mismo que estaba en correcto y eso lo vamos a ir acumulando y no va a aparecer esta matrícula que dice acá es que lineal toma 30 segundos de 15 a 30 segundos el ska lineal sobre descriptor existe es decir hacer 5 mil buscadores 100.000 lectores cuando corres bibi y luego vamos a ir haciendo pez ya vamos a reducir la dimensión a dos dimensiones y sobre ellos sobre el espacio son los vectores en dos dimensiones calculaba el vecino más cercano y vemos que tanto se aparece a los vecinos de la dimensión 128 y resulta ser que en los 2 % que se mató incorrecta normal pero el tiempo es rápido sobre los dos segundos con repetidos 30 segundos aquí rápido pero muy malo que pasa aquí y bueno aquí la precisión menor marcando e interesante la mitad qué pasa si reducimos a la mitad de los vectores y tenemos como precisión un 83 por ciento también entonces podemos votar la mitad de las dimensiones y los vecinos más cercanos se mantienen en más de la mitad nos besa y bueno y su velocidad se redujo como igual [Música] con respecto a los 30 segundos [Música] bueno esto el efecto para la escritura sí pero qué pasa si probamos en nosotros de fase sobre la misma cantidad mentales con las mismas dimensiones digamos de la misma discusión 64 y la nación 64 de la precisión legalmente organicidad cultura nación pero pero si lo vemos con menos ejemplo en 1646 decisión y en 1620 más fácil de conservar sus vecinos más cercanos y ahí todos los similar que hicimos con los árboles pero lo hacemos con con la búsqueda con pasear y aquí estamos viendo efectividad de su eficiencia recuerda que esto en los tiempos en el punto óptimo es la esquina inferior derecha y aquí sobre las curvas de los 22 escritores y eso lo hace el equipo crezca lineal a costa de no encontrar el mismo resultado y bueno se ve aquí que las curvas son harto peores que lo que logramos con los árboles anteriores de árboles con este mismo demasiado conseguíamos del orden de 95% de precisión del vecino más cercano en el tiempo aquí como 5% al tiempo tenemos precisión 15m quien sea si bien es bastante usado y se puede hacer mejor con otros con otras técnicas de examen eso sí hay que decir que es para estos centros de diversión 128 truco para ser más difícil si podemos con descriptores mucho más largo por ejemplo 10.000 dimensiones con muchas correlaciones y si quieres sea empieza a funcionar mucho mejor cuando hay demasiada redundancia bueno [Música] es decir que para finalizar que con pese a su método lineal más organizado no supervisado por qué tenemos conjunta mentoring y usamos todos los vectores se pueden hacer un método no lineal con la medida que sea aquí se llamarían especial de todo se puede ser algo útil sea supervisado esto al menos recuperación de información no aplica mucho esto pero el caso ha clasificado a decidir se aplica y decir que si tenemos un vector que sabemos que son de clase 1 clase 2 hace una reducción de inicio pero que sea panelas información no aplica mucho porque en general sujetos no supervisaron bueno y hay otros métodos que prometen cosas parecidas con este nombre y en especial vamos a realizar uno más adelante los textos la tensión a antich análisis vamos a ver de documentación o material sobre explicaciones como el ejemplo que vimos aquí antes
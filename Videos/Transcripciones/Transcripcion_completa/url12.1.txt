 hola en este vídeo vamos a hablar sobre ti planning y cómo podemos usarlo para hacer recuperación de información multimedia en el display precioso unos diez años atrás y logrando unos resultados sorprendentes en procesalmente imágenes y en particular el problema de clasificación de imágenes él fue creó una nueva forma para analizar imágenes que dejó obsoleto de todas las técnicas anteriores y que ahora no interesa como podemos usar esas técnicas para poder hacer la cooperación de información multimedia que los clasificadores sirven para clasificar pero uno puede usarlos para calcular el descriptores globales y similitud entre imágenes ya que los interesantes que son de información y por eso lo que vamos a ver ahora y otra técnica donde nos sirven en herning es para poder entrenar formas de combinación de escritores podemos entrenar impulsando machine learning y la mejor forma de cómo combinar la información de audio con información y esa lógica la concatenación sino que podemos ser funciones ya que combinen de forma más compleja estas dos fuentes de información bueno esto lo dijimos un vídeo del premio de repaso the machine lamming de blandi se refiere al uso de redes neuronales grandes o profundas ideas pero no es sólo eso porque esa red existe ambiente de los años 60 del complejo impresor de las redes las multiplayer presentan estas redes con capas uno puede ponerle 10 capas a una o una multi layer por el sector pero eso no lo transforman de eso la característica clave que quiso lograr los resultados que hay que lograr ahora que analiza está regionalizando directamente el contenido multimedia analiza directamente en la imagen el vídeo el audio el texto es decir no hay que hacer ningún idealmente ningún análisis previo si no entrega la forma de analizar el contenido multimedia esa es la característica clave y por tanto como está analizando la imagen en alguna parte va a generar un descriptor de contenido [Música] que tiene distintas arquitecturas ya para poder procesar distintas fuentes de información y todas esas arquitecturas como siguen la misma filosofía de hamas pueden ir y sensores pueden ser combinadas de distintas formas entonces entonces son como bloques de lego que se van enlazando y no puede ir combinando una capa una campana red convencional con capas de clapper sector con recurrentes de un forma bastante libre y eso da algo súper poderoso para poder procesar datos múltiples características y es que como gusta en redes que tienen muchos parámetros muchos pesos y además mucho hiper parámetros y entrenarlas para entrenarlos no requieren de muchos datos grandes las bases de etiquetados y además un poder de cálculo muy grande por tanto es no le quieren mucho muchos datos limitados bueno como muchos datos generales y mucho poder en el proceso y por tanto esto es la barrera de porque esto no se podía haber estudiado en los años exactos y apareció ahora al 2010 como era antes de hablar inglés clasificación de imágenes aquí todos que tenemos tres tipos de imágenes aviones gatos y perros y queremos decir dado una imagen es decir que lo que hay en esa imagen de sí que añadió un gato o un perro tradicional tradicional lo que hay que hacer es que uno usa bueno aquí hay una red de marketing el perceptor también aquí uno podría usar un súper vector machine un rango forest este trabajo clasificador porque porque en la forma tradicional una imagen hay que calcularle un descriptor del contenido un vector y ese vector el que se especifica y después una vez los vectores que desgastó del ente para hacerte entre sí y de hacer distintos los vectores de las fotos de ver los vectores desde ya pero esta experiencia que es cómo convertir una imagen en un vector es lo clave y la mayor dificultad nosotros les gusta hemos visto algunas formas de cómo calcularlo de cómo calcular de escritores de contenidos acierto por histogramas de colores y trama de colores programas de bordes máquina extras que se llama el juego y descriptores locales cif surf isa variante o los books que solar la delegación de escritores locales donde aquí aparece una que estaba el rector y todas esas formas son formas para poder generar este descriptor que representa el contenido lo que espero la dificultad mayor es cómo grabar de alguna forma esta generación del vector y tiene que representar el contenido que permita discriminar una ala aquí a la nación del delgado y está el ejemplo que uno tiene que saber cuál es la característica que permite discriminar un gato negro doctoró negro y en realidad y no siendo el ejemplo es difícil cuál es cuál es la característica quien nos permite discriminar y ver las fotos de los píxeles de un gato negro y toma la foto de la expresión del peronismo terminantemente tiempo el atributo son los bordes los dos tienen colores super parecidos de forma muy parecida a los directamente no van a ser tan distintos entonces sólo aquí y es la dificultad con la que esta generación del vector que representa el contenido tenía que representar el contenido clave para poder discriminar el gato antes cuál es la clave que aquí cuál es la característica que hay que representar que hay que guardar aunque hay que preocuparse de que eso era eso no es eso porque los resultados no eran muy buenas lo que sucedió en el año 2012 que apareció en las redes convencionales para este problema real existían darthés pero ese año fue donde se aplicó en este problema y se mostró que tiene resultados muy buenos y la diferencia clave era que en no sé no sabía que uno ocurrírsele la forma parecida el escritor sino quien uno entrena la forma de analizar la imagen importante una parte de la imagen de los píxeles mismos de la imagen y uno utilizan los operadores de convolución de la conclusión de que es una una ventana del instante que busca un patrón dentro de la imagen en este caso se va a buscar un patrón y es el filtro que tiene unos pesos adentro que son los pesos que llevan dentro decir triste este este filtro que tiene ciertos plazos va a ir deslizándose entre la imagen buscando la aparición de ese patrón y el resultado de ese deslizamiento es una nueva imagen posiblemente más chica uno levemente más chica por los bordes porque porque no puede salir de la imagen y ahí hay unos píxeles que nos culparon pero aparece un resultado y esta imagen es un mapa del resultado del filtro en cada una de los de la zona de imagen de los pinceles mi imagen porque importante hasta aquí es el resultado es el resultado del filtro y un mapa diciendo dónde dónde es y eso no lo somos y lo vamos a hacer varias veces y por tanto vamos a generar una nueva imagen la imagen original de los colores entonces tenía tres canales descargue rgb ahora vamos a generar una nueva imagen que va a tener más canales un canal por cada filtro y esto la grasa esto es que entonces esto se interpreta como la otra imagen a la que podemos aplicarle a las fiestas y ahora podemos buscar apariciones visuales dentro de el resultado de los filtros anteriores y estos filtros son más interesantes porque ahora empiezan a buscar formas para unir los filtros básicos iniciales ahora son filtros más elaborados porque ahora son filtros que combinan las situaciones y te genera un punto un nuevo conjunto y cada uno de estos nuevos filtros va a generar una nueva imagen imágenes de una profundidad bastante más grande puede ser no hacer 92 y luego todos estos resultados los pinceles que en ese entonces contienen un mapa de apariciones de los filtros del segundo nivel es que es una unión de las apariciones de los historiales bueno y esto se pueden haciendo los filtros se pueden concatenando varias veces hasta que finalmente uno tiene una imagen y esa imagen que se línea lista y se convierte en un vector y luego viene una capa de clasificación el mismo vector de la misma y está enlazada con el resultado de la última convención nada esta parte es clave porque se unifica el clasificador final y que en el que decía sí que hay una vid un gato pero con todos los filtros anteriores en una única red importante cuando se entrena esto una es él una imagen de entrada entonces va a entrar el avión van a operar todos estos filtros y luego va a decir va a llegar al final va a dar un resultado y el algoritmo aprendizaje dice lo que lo que acaba de ver el resultado debe de ser la salida 100 entonces se había tenido otra salida que opera el algoritmo del pro cristian para quien tiene que corregir los pesos para que se muevan hacia hacia el resultado que uno desea y lo interesante que como esto está todo enlazado el back pri para james jones va pasando y el back ver vacation puede afectar al no filtre fielmente los filtros visuales son los que se entrenan y uno entrena al patrón visual que hay que ver pues hay el patrón visual que al que logra discriminar aviones de hidratos de ramis por tanto vayan tanto de imágenes y van a aparecer estos filtros van a girar a la salida y eso sería luego se corrige y se corrigen los filtros para que se mueva el filtro hacia el norte si a nosotros nos quiere discriminar en gatos de perros de viales importando mostrando en el suficiente ejemplo de fotos de gatos pero ellas vienen entren a los filtros visuales que permiten discriminar y uno nunca tuvo que programar nada de existieran bordes triángulos de oreja o los círculos de ojos eso no se da cuenta sólo el algoritmo de entrenamiento y los filtros mamarios si quieres o relevante van a ir apareciendo siento que detecten estos son los clasificadores pero lo más interesante de aquí es que bueno aparte de que el filtro al que se entrena es que en una parte queda claro que aparece un vector y por tanto es éste un descriptor de contenidos quien fue entrenado con los filtros entrenados aparecen finalmente un vector y el que se está clasificando y ese vector este escritor de contenidos que nos permite que nos representa la imagen y nos permite calcular distancias imágenes y por tanto los gatos deben estar todos al que entre así pero aquí más interesantes las fotos la distancia entre el vector de este gato negro y este perro negro la distancia detenidos dos deberá ser más cercana y en la distancia de la foto cualquier las fotos aparecen y por tanto ahora ya ground si unos gustos escritores entrenados ahora la similitud entre imágenes continuas otras distancias no es decir este grato pues a uno no dice solamente en algo tan tan tan discreto como decir estos son gatos y soto dos gatos y estos son para los otros perros sino que ahora no puedes pensar a calcular como que aquí esta supuesta imagen o me voy a empezar a capturar datos parecidos y perros parecidos e incluso si es que el gato se parece más a un perro entonces ahí hay distancia entre imágenes y eso sólo lo logra y por eso lo llegue hay que entrar porque este el descriptor que nos permite esta recuperación de información
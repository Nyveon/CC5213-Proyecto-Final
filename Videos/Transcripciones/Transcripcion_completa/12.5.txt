12.5-Deep learning-Entrenamiento, dropout y otros
https://www.youtube.com/watch?v=x1T2Z0h9wuQ
 así como está la función de activación hay otras formas activar de entrenar una red que hay que tener en cuenta está entrenando en alguna red convencional y con imágenes lo más común es que las imágenes tienen que ser normalizada y esto es un paso típico de que uno espera que como no va a estar jugando a positiva negativa activado desactivado lo más fácil para que entren a todos estilos datos de entradas estén centrados en cero y sean tanto positivos como negativos y eso consiste en que las imágenes de la imagen son cuando son de 8 bits tanto 62 56 25 y 50 es importante que x central es una forma directa es restarle 127 127 117 si uno no sabe nada la imagen de hecho estudian es razonable pero en realidad usualmente empezará a ver el data set de imágenes y se dan cuenta que en realidad la imagen promedio del color de píxel promedios no es 120 ciencias 217 sino en realidad un valor un poco más alto un poco más bajo el usualmente están por ahí también entre 105 y 106 y algo como esto para no aguar de los números del rímac kinect pero un número de sentido en el medio donde el final de fase de vivir [Música] porque uno esperaría que todas las fotos cuando uno usa las fotos de la misma cantidad muy claro muy oscuro incluso en vez de usar píxeles promedio entre yale que se estila cuando entregan y martínez en usar la imagen chrome y promediar entonces uno por medio del píxel para cada uno de los píxeles está su promedio de alta tasa y es el que se va para que quede efectivamente centrales a la imagen en promedio se necesita otra forma otra pequeña variante de cómo se entrenará la reina sienten aquí ahora su estilo entrenar por mini baches y en vez de usar todas clases para entrenar y hacer los ajustes de entrenamiento luego de ver todos datos de la mente no saben ganar una pasada una época a todos los datos y luego ajustar los pesos es decir nos cuenta que todo converge más rápido todo mucho mejor si nos va actualizando los pesos en infracciones del entrenamiento no hay que pasar todas las entrenamientos para ajustar los pesos sino que con un pequeño grupo de datos uno que ajustando más rápido y eso hace que avance los pesos y que converjan más rápido más en barro y dos osos pero la práctica gratis y los otros conceptos clave del learning diesel en el paso con el cual uno que actualiza los pesos de la red y eso ese paso es clave de qué nación es muy grande ningún chico porque sea muy grande los ajustes van a ser muy muy muy grandes y la red nueva conversión si son muy pequeñas la renta danza tampoco puede encontrar un cambio pequeño y me va a llevar en un mínimo de muy chico y ahí es donde uno empieza por fin un varón grande y luego que se vayan reduciendo del ibi y esa reducción no parece la línea constante pero es mejor si va dependiendo de como el diferencial que va calculando el impacto va desde los diferenciales de m con que se ajustan los pesos dependiendo de la magnitud de sus diferenciales entonces él es por cuatro condena de aversión o algoritmos que hay muchas variantes ya sería malos optimizer si es que uno puede decidir cuál es el optimizer que uno va a usar para entrenar la red y hay bastante pero como relación al niño que no funciona funciona bien ya sin entrar en más detalles ya eso para el curso de maquillaje otro concepto que para entrenar que es interesante que se concentró para dos out es una técnica que dice que cuando no está entrenando la ley está yendo a conexiones el over feet ml p siempre lo participando con el té allí todas las utilizan para hay mucho para evitar en el lugar si se refiere a que puede como tienen muchos parámetros como son millones de parados de llaves y son más parámetros que datos que la red puede empezar a aprenderse los datos de entrar y darse cuenta que cuando llega el vector no es el vector uno que tiene cierta salida en vez de aprender en los diferenciales se va a aprender dijo el vector 1 al vector uno tiene esa salida llegó el segundo vector al segundo sentarte en esta salida y en realidad no aprenden con el finalización que se aprende los datos de atrás para que pueda suceder eso para que el la salida depende directamente de una entrada tiene que haber conexiones fuertes entre los datos para que se pasen el dato por ejemplo entonces un perceptor de la primera capa va a decir el bien el dato número 5 y después en la capa siguiente tiene que haber alguien escuchando a ese perceptor que está detectando el dato para pasarle para basar el dato a dios el dios dato 5 y después para pasar sobre la siguiente capa para que la última capa entregue el resultado que le corresponde al sector se encuentra entonces porque va apareciendo la red van apareciendo conexiones fuerte para bueno para poder pasarse el dato del dato que para poder darle salida a esa visión de cómo operar en estos aprender bastantes y para evitar eso es que durante el entrenamiento en cada etapa del entrenamiento las conexiones entre entre percepciones se van desactivando en un porcentaje por tanto él no siempre es por ejemplo este perceptor estaba teniendo una conexión fuerte con él está pasando el dato de escuela el vector de entrada con el drop out la idea es que en cada etapa inserto porcentaje un 20 por ciento de las conexiones cuarto un 5% las conexiones no existen son cero y por tanto el este percepción de vengan dependiente todo un poco porque porque durante el entrenamiento no siempre va a estar activos amigos y como no gastar y tiene que estar decidido entonces el libro paul obliga a que los perceptores dependan de todos los costos de la cab áfrica informa un poco más dijo y como y rompen todas estas conexiones fuertes y eso lo trata de invitar en el hogar fit y de aprenderse los datos como un truco durante el entrenamiento en la práctica al menos las cosas es funciona con un valor y van creando como 50 que tiene un 20% que funciona y el resultado en la red queda más general y aprende más los datos se aprende más en la tendencia y entrenamos con los datos pero con un factor pequeño en x 50 por ciento de cada vehículo es mucho de ahí se arruina el resultado el truco de la regularización la regularización que dice en el dato la regularización dice que cuando hay pesos y cuando lo q responderán los pesos de una vez esos pesos que una espera que sean más buenos distribuyen dos y al momento uniforme entre que le dé más favorezca uno bajado más que otro pero quien no quiere unos valores 000 mil 000 si pasa eso es porque ésta está mal varió la pérfida y está vendiendo ruido en una experiencia más uniforme y como no pueden forzar a que los pesos sean más uniformemente así es que en la función de costo está la magnitud de los pesos y con eso la idea es que cuando está entrenando además como el objetivo de que sus casos sean todo lo más bajo posible [Música] y el otro para entrenar las imágenes de entradas se pueden multiplicar por muchos y es que sí que hay una foto de un gato entonces la imagen tratada en 5 grados también es un cast y la imagen reflejada también es un café y un consumidor ajuste los colores un poco y también son gatos de por vida sigue siendo lado entonces grupo de jugar a todas esas variantes para más datos de entrenamiento y uno puede generar millones una canción que era de mil datos de entrada cada uno debe de generar entonces mil variantes y esas variantes que pensarla eso sí porque tienen que ser transformaciones que no afecte el resultado final y para hacer eso ya depende del problema que consuma estando para hacer una documentación internacional ciertamente yo aquí estoy a poner la imagen totalmente negra y es un ejemplo ni tampoco y otro truco de transfer learning bueno más adelante en un ejemplo de audio donde uno puede partir como se usa también de que una parte entrenando con imax y metiendo y uno uno quiere es tener por ejemplo un clasificador de tipos de deber y la raza y gritar fotos de razas de perros de la red convencional que entren a eso uno puede partir con una red entrenada genérica de imágenes para preparar todas las clases y la especialista en una red desde cero cappa quien la detectan ha sido simples el ánimo entonces el mejor partido no a partir de ser el serbio particular voy a entrenar y es que si no bueno detectando imágenes uno puede entrenar una red de audio a través de los vídeos entonces si no detectamos los pájaros entonces no puede detectar y no tienes vídeos de pájaros y esos vídeos están con el canto de los pájaros entonces no puede usar la red visual que detecta bien los pájaros para entrenar el audio que aparece en ese mismo momento cuando aparece en el baja y entonces una alterna de una red que etiquete audio y entrenando lo que ya saben con como una buena forma de transformar
 en este vídeo vamos a hablar sobre titular link para presentar texto del por qué importante esto para la recuperación de información multimedia es porque el texto es una forma de usarlo para las consultas los usuarios pueden preguntar la cirh consultas en texto cuando tengamos documentos multimedia y también contienen texto además de una imagen además de tener la imagen tiene títulos o tags etiquetas y hay que saber cómo poder procesar y representar a ese texto de déu learning ofrece distintas formas para representar contenido y los más interesantes ofrecen formas de cómo combinarlo con los otros tipos de descriptores la parte clave de cómo se representa el texto es lo mismo en la aventura acción porque el texto libre es algo que no ha estructurado una cadena de bytes string pero para volarse el análisis de ello necesitamos algo más estructurado de los vectores entonces la forma de convertir un texto de vector que ya hemos visto lo quiere enfoque tradicional a través de back of words y todas las técnicas que desde de esa línea y con el enfoque de dibujar min porque uno y es muy simple que se llama y él el cole walcott el código es primero tenemos que definir todo el vocabulario de la casa y definiremos el vector que define a una palabra como un aquí tenemos esto de aquí es el largo del vocabulario y se siente en la palabra no se desgastó porque aquí dentro de todo esto es el y de la palabra y aquí va a estar aquí esta receta y la palabra y la palabra tiene un banco y está representando algunas palabras del vocabulario de esta representación es de alta dimensionalidad central que usualmente esto de aquí es del orden de miles de pesos y ese esfuerzo tiene muchos matices y como representaba una frase si la frase tiene diez palabras y es importante si aparece al lado del enfoque juliano de la representación mundial cuando hablamos de robots donde no está entonces que si tenemos la palabra el gato y gatos el gato estar aquí hidratos estar ahí nosotros en otras coordenadas en otra dimensión encuestas son palabras totalmente distintas candidatos con gatos están distintos convocados con [Música] y sin embargo hay que decir que queremos hacer más ajustado al lenguaje y vamos a ir estos otros modelos y el concepto base aquí ya lo hemos hablado cuando hablamos de bago words es que no queremos ser tan preciso en el enfoque en el en el sentido lingüístico sino que queremos ser modelos simples ver que se ajusten con mucho atrás que modelo simple que en especial para cuando sus problemas difíciles y difíciles de entender y de representar un modelo simple resultado con muchos datos supera en calidad de representación a los modelos complejos resultados con pocos datos el lenguaje un modelo complejo de lo como lo hablamos antes de todo en el lenguaje que es humano importante así como tiene reglas así como tiene sociales además cambia en el tiempo y depende del uso de las personas y cambia también de la zona geográfica entonces sólo es difícil generar reglas a mano que uno está decodificar como ese lenguaje y por eso es quizá lo mejor hacer el modelo simple y cargar leer ver cómo está cómo es del lenguaje mediante grandes cantidades de texto en español por ejemplo tomar todo wikipedia o digitalizar muchos libros y ver cómo está escrito tanto en español y debe tener ojalá todas las frases escritas en español posibles de válidas y de ellos tenemos estadísticas y elaboramos lenguaje y un modelo de cómo es el idioma se entiende la idea y mientras más grande esto mejor va a ser el modelo y no hay que empezar a pensar uno en cómo de cómo es el español que tiene un sustantivo nuevo verbo y hoy surgiendo predicado directamente de frases por ejemplo un modelo importante consiste en cómo poder encontrar sinónimos los sinónimos son las palabras que es palabras distintas quién significa lo mismo y una forma más algorítmica de encontrarnos en buscar palabras que sean intercambiables entre sí es decir qué en una frase que contiene una palabra y que uno habla de intercambio por otra y no cambia en nada su sentido de sus funciones y eso lo podríamos encontrar entonces si teníamos muchos textos en español podemos encontrarlo buscando palabras que aparecen con su mismo contexto contexto entendió comunidad como las palabras que espera alrededor de por ejemplo sinónimos elegir y escoger la idea que si hay alguna frase dentro de nuestro gran corpus de españa de alguien escogió hablar a elegir por ejemplo una gusta legible después va a aparecer otra palabra y donde diga escoger y esto me parece extraño y para parar para que nuestro pc extraiga el palabra donde diga esto me parece raro fui al dentista o fui a los probó y van a aparecer indistintamente entonces cada vez que aparezca una palabra que diga al dentista y entonces va a haber otra frase igual pero con la palabra doctor no entiendo entonces que esto si sucede eso entonces nos podemos dar cuenta que esas palabras son funcionarios pero por supuesto sin embargo es suficientemente bueno no exacto porque porque de hecho los antónimos los antónimos se comporta bastante bastante bien son bastante intercambiarlo con los santos y los mismos contextos cierto el más feo y bonito y el uso que se les da a la misma frase que mira feo podría decir bonito de ahí ahora frase manía que podría existir en el cuerpo así que hay que tener ojo con este enfoque porque a veces pasa que los antónimos o palabras relacionadas por ejemplo los colores y dirigir a todos los colores son bill intercambiables entre sí todas las frases y eso hace que estas canciones ok pero lo que vamos a hacer es que estos sabemos que no es exacto pero es suficientemente bueno y vamos vamos mantener la simplicidad del modelo entonces cómo calcular el hilux ya menos webb ellis que es tratar de representar las palabras por medio de vectores que donde la distancia entre las palabras se ajuste a sus diferencias vamos a intentar que sean vectores y nacionalidades los one hot water y anti nación de 10.000 bien aquí eran esfuerzos hay quien lo que quiere porque sean ni personas ni quiero que seas vectores de indignación por ejemplo usualmente se destila de algas 23 100 donaciones a 300 naciones recientes investigaciones pero densos usan todas esas dimensiones y que en la distancia entre estos vectores y sea algo que represente sido palabra están cerca es porque es export que son sinónimos y si se alejan por cierto no hablan de mí [Música] entonces lo que vamos a hacer es que primero estos vectores esta distancia la vamos a obtener revisando nuestro gran cuerpos del espanyol y vamos a ver las reglas relación entre las palabras pero parcial como hablamos los sinónimos y vamos a entrenar una conversión que va a partir del modelo cuántico al modelo de efecto retrasos él iba a ver el hueco donde en la forma es que vamos a partir con vamos a hacer una pequeña red poco profunda donde vamos a entrenar dado dos palabras dado su contexto no quiere decir la palabra que continuamos por ejemplo dice que mira por mí todos los días y aquí dice que vaca qué palabra ahí y de hecho hay muchas opciones mirándome no sé cómo esto se codifica en esto como se entrena es porque la palabra me estás está acá son codificación agua hot lo que importante la palabra min hasta el cuello va a ser un 1 en alguna coordenada el gato va a estar en alguna parte nada va a tener unos ídolos van a ser cero bueno me parece también y todos va a estar después de los días de un contexto de 3 y esto hay que decir entonces en la palabra final la salida tiene que hacer alguna palabra válida esto lo entrenamos tomando para hacer el ejemplo de nuestro corpus y por tanto supongamos que la ley de salud que él gana set dijo decía en la delegada de salud por tanto su respuesta correcta era un 1 en la palabra salud pero nosotros no sé cómo nos haya gustado entrenando ponemos cualquier otra palabra de bien no no y 1 y 0 que no había significa que respondimos con un 1 en la palabra y en el entrenamiento decimos todo que no está mal y con back pro para kate son que decimos tienes que no era avión iba a hacer la conexión sector y que ajuste sus pesos para que para esta entrada de ellos arriba luego de suficientes pasadas con muchos ejemplos i se va a encontrar varias veces con el frase de este estilo y va a ir viendo todas las posibles palabras que van a ir llevando acá entonces tal que hay aquí estas palabras tiene que ser la misma los vectores implícitos que iban a ser los que íbamos a sacar después de sacar van a ser los mismos y él y los sinónimos semana quedando van a ser lectores parecidos y luego vamos a ir viendo todas las posibles formas en que en que esto tiene que convergiendo aquí entienda cuáles son las posibles formas de rellenar esta frase y esto lo tenemos que hacer y esto lo tenemos que hacer para distintas frases entonces supongamos que ahora tomamos otra frase y ahora me rasguñó a todos de quién número una palabra entonces hay para ver palabras difíciles con el primer ejemplo era más difícil porque hay muchas posibles opciones y en cambio en esta estábamos menos fácil porque como por por gramática que hay que decir los opciones por una frase y gramática entonces ahí va a ir aprendiendo también un poco dramática entonces cuál es el punto aquí es que si esto no entrenamos con suficientes datos y luego aquí será más en la gente sabe que jugar pero ya no más tantas más no va a fallar tanto sino que va a ir aceptando de esta forma y luego tomamos en los vectores más contiguos y vamos a sacar de esa red entrenada cuáles son los vectores que el mbe nikkei que entreno para acabar en este enfoque continuo es vago words es bastante más fácil de entender porque también en este paper mister es mi color de propone de todos los enfoques de cómo se compensa y cuál es mejor y propone lo que saber continua se escribirán donde dice dado una palabra múltiples y puede su contexto entonces él lo que sí tengo un contexto de dos y digo compre y aquí no es equivale a 20 compre volumen la palabra compre hay que que hay que jugársela por cuáles son las palabras que van anti cuáles son las palabras quién vienen después desde el de la france siempre por supuesto y esto es imposible acertar pero bloque uno va haciendo es que esta es la medida que uno lo va entrenando y se la juega al azar por el otro le dice cuáles son va entendiendo las relaciones de palabras con compre cuáles son las que usualmente vienen antes cuáles son las que usualmente después de esta palabra cumple muchas veces pero no en este contexto previo no está todo el vocabulario sino que hay un subconjunto más bien pequeño de palabras que aparecen antes de parar de la palabra cumple y lo mismo para después de consumición de entrenamiento va a ir entendiendo o va a ir entrenando más en esta relación entre palabras éstas realizaban las guardias a palabras y otro ejemplo de entonces si va a ser el día cuando aparezca como compre vas a ver que hay ciertos conjuntos palabras que son distintas las palabras que acompañan a nadie esto se está otra forma aparecen otros 20 tiene las mismas propiedades que el anterior hacen dos entrenamientos dos formas distintas de ver con esos cuales bearings que vamos a ir alternando en la idea es que de esta forma las palabras que ocurren en forma intercambiable los sinónimos van a ir van a ir siendo más indistinguibles de la vuelven va a aprender que para poder entrenar esto tiene que descubrir estos volúmenes a partir de vectores de dimensión 10.000 tiene que llevarlos a un espacio de animación 300 por tanto tiene que poder comprimir información y para comprimir información tiene que encontrar patrones como ni los patrones comunes son estos estas palabras que son similares y corresponde a las actuales cercanas [Música] luego una vez que tengamos todo este conjunto de vectores en los sinónimos para tel es vectores cercanos entre sí es decir distancias cercanas a cero pero más curioso es que van a ir apareciendo reglas gramaticales dentro de estos en phoenix porque porque en el español y muchos otros idiomas al menos luego occidentales cuando una palabra cambia cambia de contexto por ejemplo el singular o plural también van cambiando todas las palabras alrededor o cuando cambia una frase de masculino a femenino y también cambian los adjetivos los artículos alrededor y por tanto por ejemplo si teníamos la palabra el día la frase del día soleado y eso tiene cierto en el día soleado en ciertos sectores también aparece la frase los días soleados y entonces y entonces hay una relación hay una relación en que los guarden behring se van a ir manteniendo guardando esta relación van a ir conteniendo esta relación de como las palabras se van convirtiendo al plural en grupo el oso come con los osos con él otra frase incluidas en el ejemplo de masculino femenino el gato negro está dormido la gata níjar está dormida se entiende como qué él se convierte en la y eso hace que todas las otras palabras también vayan cambiando a su versión de femenina gato con catalán europa negra y dormido con 2000 y él por ejemplo ejemplo mar efe - el famoso doctor es santo y callado y su versión femenina sería la famosa doctora es alta y que ya esperaría pero para que él para que no se contenga en esta relación de masculino o femenino tiene que aparecer estas frases el clásico ofrece el día soleado tiene que aparecer la frase y los días soleados en alguna parte y aquí es donde aparece un un tema donde él y es una de las cosas quieren que se discuta actualmente es con respecto al sexo dentro del lenguaje y qué y que como uno está aprendiendo estamos en un algoritmo que aprendan de textos ya escritos empiezan a aparecer en esta transformación en especial cuando las más polémicas son estos de transformación hombre-mujer donde donde nos es doctor y doctora y uno empieza a ver las transformaciones de masculino femenino y nos van dando las mismas palabras porque por quien no tienen la misma distribución y las razones por un tema más de excepto desde la sociedad y es que un tema que se trata a ver cómo poder tratar de evitar este exceso de aprender de las bases pero no no tratar de descartar ese sesgo en los ángeles bueno es un problema entonces el espacio las palabras va a tener estos cambios de direcciones porque los los vectores van a tener alguna relación entre ellos y sus versiones plurales para hacer cierta relación también para mantener la relación entre ellos pero en su versión plural y ellos otros cambios típicos álvarez singular programas con el femenino está sustantivos de envíos rápidos versus rápidamente bueno el infinitivo participe de los verbos que cierto comer y ha comido todo presente ha pasado por alto y todas esas conjugaciones también se van son parte de esas transformaciones y por tanto esas esas transformaciones más dice que en nuestro espacio palabra se está capturando bien la relación de entre las palabras y por tanto es la forma en que se va a usar para evaluar por ejemplo si tomamos dos frases como gatos dormidos y la estás dormida y tratando modelar esta transformación al femenino podemos hacer una especie de analogía al ver que la relación entre gatos y dormidos se tiene que mantener entre gata y dormida y por tanto uno si no resta aquí está el origen importante si uno toma ese evento y todo se aventó al mismo resta uno obtiene este de que este evento de transformación en este sector verde con que el gato no le suma este vector verde y le va a dar el detector gata y ese mismo vector no puede servir si es que decir que está bien modelado de esta transformación de toda una secuencia de mathura fabri no éste es el vector lista la dirección la dirección en masculino o femenino y por tanto podemos sumarse la ha dormido para convertir a dormir podemos maestra cualquier palabra en masculino para obtener su palabra un femenino entonces lo que vamos a hacer es que da una medida y podemos hacer qué revisar si es que está esta tecnología estos cuatro grupos de cuatro palabras se cumplen sus relaciones de aquí de transformación más fueron femenino entonces vamos a decir que esta de aquí es una incógnita y esta va a ser aquí vamos a ver si podemos predecir la ubicación de la palabra dormida que lo voy a hacer entonces vamos que puede vector verde quien en placa agárrate le restamos gatos y nos va a dar entonces el vector de este vector verde se lo vamos a sumar a el vector dormido y no pagar un vector x y tengo que comprobar si que x nos va a dar el éxito de cualquier y creo que comprobarse que ese vector x esto no es dormir ahora que sea exactamente dormido y sea exactamente eso es difícil por último numérico pero lo que van a ver otros vectores de palabras y tenemos que calcular el más cercano la palabra válida más cercana y tengo que ir si es que la palabra valía más cercana de este vector es era efectivamente dormida entonces se cumplen la analogía y entonces lo que vamos a hacer es evaluar un espacio palabra mediante muchas analogías incluso se puede separar la analogía como analogía sintáctica la que en relación con un cambio en bien relativo a las palabras y a las terminaciones por ejemplo aparentes y aparentemente como evidentes y aquí en x haciendo las operaciones de estas palabras y ves que este vector x coincide con el interés de su vector más cercano es evidentemente es la energía sin sintáctica pero también hay energía se mastica ya que son un poco más de alto nivel como esta que es relacionar un país con su con su capital de indisciplina en verín capturar un país con su capital si tienes suficientes textos por ejemplo noticias del mundo de los noticieros y es común que en las noticias se hable de un país y sus y su capital fíjate la frase de la capital de no ser en atenas la capital de y blablabla entonces y otras otra noticia que viene no sólo en la capital de noruega blablabla y hay manera para haciendo la capital de más ser el nexo entre ellas para crear esto se va capturando esta relación en el trazado portugués con 20.000 analogías ahora en inglés o sí con transformaciones al adjetivo adverbio opuestos lo opuesto se refiere como a los antónimos fáciles de antónimos que es consisten por el prefijo esto es algo antiguo bueno creo que el tiempo verbal lo plural cooperativo sobre el adiós un tema de y españa faster son son simpáticos porque es solamente se preocupan de desistir en la terminación o no [Música] y las relaciones matemáticas qué país capital del país moneda moneda digamos nombres del dinero espeso y en eeuu entonces tratar de relacionar país con su moneda o un estado aquí se refiere un estado de eeuu con algunas ciudades estados y las relaciones hombre-mujer más que nada más que ya femenino como está aquí que como un clásico cuando se explica esto de el hombre o mujer wayne rainey entonces esas son las temáticas y lo que hacen es que entre estos dos enfoques que vimos por el continuo y el plan y generan espacios de palabras en distintos y que el modelo mak of words ven experimentalmente que vagó words genera un vector que la analogía sin práctica las razones muy bien no falla en la nanociencia batidas y que él es quien gran y que es que tiende a representar y generar un espacio palabras con tiene presenta mejor las analogías temáticas pero peor la cinta activa pues uno va a ver en realidad una prueba en el resultado en los scripts funcionan mucho mejor por lejos de las temáticas y funcionan un poco pero reglas sintácticas pero después en el resumen global finalmente los script también con un resultado mejor global para las analogías que se probaron y nacional.el a veces es una forma de evaluarlo pero no es que uno no es que un buen en berlín se calcule se cree para resolver energía excepto no nos da en las formas no nos fuimos a 11 nos gusta aún si uno quiere tener una base de datos de capitales de países con capitales uno no entra en un work reding no pero se usa como para ver si es que está capturando bien las propiedades del lenguaje por tanto bueno oye una espera que cumpla la analogía fiel pero no es lo que uno puede para que se usan para las tareas que es bueno llamado a continuación que es la de clasificación de texto o búsqueda información crítica búsqueda de frases similares y que en realidad se indique valores del problema final y esto de las analogías de una evaluación [Música] media ficticia pero pero que sí permita saber la calidad global de él berlín behring quien era un poco en consideración porque si uno se enfoca solamente en una pierna analogías uno puede terminar con un espacio palabra perfecto para analogías pero aquí es cual funciona muy mal para [Música] bueno el 2 el espacio las palabras de vinos dependería por supuesto que va a ser distinto a el espacio las palabras entre español e inglés ahora hay que decir que es actualmente hay trabajos recientes que están trabajando y donde sea multilingual al mismo tiempo hay que tener mucho más espacio para entrenarlos con wikipedia de todos los medios de todos los idiomas pero después es algo fuerte lingual ofrecen 11 vectores de palabra había interesante porque además hasta la dirección de cambio de idioma y que sea súper bueno después para traducciones en todo caso si quiero convertir lo mantenemos sólo en español ya hay un problema porque depende del lenguaje que se cruzan dos es muy distinto entrenar vueling usando textos de noticias que usando / no se entiende con noticias después difícilmente va a poder hacer relaciones de fichas clínicas donde habló mucho de enfermedades jason de aquí sobre el uso para entrenar en el uso correcto no dudo o legal sí que son leyes o informa dice no sé de documentación de alguna libre [Música] en español y eso sirve para cualquier idioma español tipo de país y no sólo eso y además cambiar entre países así que depende el conjunto entrenamiento porque en sus claves como ya lo dijimos y lo huelen medir para contener los círculos sociales existen en esos textos y si es bueno y hay ejemplos de evaluaciones donde las palabras masculinas se relacionan de éstas más cercanas con ciertos términos y los premios se han realizado por las dos términos que no tienen por qué ser así pero es tan así porque sí [Música] y que los vectores puede ser por eso que de seguro idealmente lo mejor es estar de los vectores pre entrenados unos ahora un gran problema proyectos de entrar vectores nada es fácil pero ese plan depende de una